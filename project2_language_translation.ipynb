{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxI_KUvci_6u",
        "outputId": "542260f1-830d-4f2c-b122-63b9dedf5236"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1VMuZOrraBle"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load the training data\n",
        "train_input_texts = pickle.load(open('DS_5_train_input', 'rb'))\n",
        "train_output_texts = pickle.load(open('DS_5_train_output', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Q1pHecwtcjPf"
      },
      "outputs": [],
      "source": [
        "text_pairs = []\n",
        "for line_ip, line_op in zip(train_input_texts, train_output_texts):\n",
        "    \n",
        "    output_lng = \"[start] \" + line_op + \" [end]\"\n",
        "    text_pairs.append((line_ip, output_lng))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DAQD7PB-crqx"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.20 * len(text_pairs))\n",
        "# num_train_samples = len(text_pairs) - 2*num_val_samples\n",
        "num_train_samples = len(text_pairs) - num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
        "#test_pairs = text_pairs[num_train_samples + num_val_samples:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-kd7tnqkiZE",
        "outputId": "8a065e7c-4261-4187-ffd0-aeaec11c9452"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "H5hqgQ2lcsaF"
      },
      "outputs": [],
      "source": [
        "#Vectorizing the Language_1 and Language_2 text pairs\n",
        "\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import re\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "strip_chars = string.punctuation + \"Â¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(\n",
        "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
        "\n",
        "vocab_size = 40\n",
        "sequence_length = 200\n",
        "\n",
        "source_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "target_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "train_lang1_texts = [pair[0] for pair in train_pairs]\n",
        "train_lang2_texts = [pair[1] for pair in train_pairs]\n",
        "source_vectorization.adapt(train_lang1_texts)\n",
        "target_vectorization.adapt(train_lang2_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MkNONcVVc-QC"
      },
      "outputs": [],
      "source": [
        "#Preparing datasets for the translation task\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "def format_dataset(lang1, lang2):\n",
        "    lang1 = source_vectorization(lang1)\n",
        "    lang2 = target_vectorization(lang2)\n",
        "    return ({\n",
        "        \"language_1\": lang1,\n",
        "        \"language_2\": lang2[:, :-1],\n",
        "    }, lang2[:, 1:])\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    lang1_texts, lang2_texts = zip(*pairs)\n",
        "    lang1_texts = list(lang1_texts)\n",
        "    lang2_texts = list(lang2_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((lang1_texts, lang2_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TQyLN-TdW8h",
        "outputId": "55ccafac-ddfa-4a04-8182-8e5c8d2a15ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs['language_1'].shape: (64, 200)\n",
            "inputs['language_2'].shape: (64, 200)\n",
            "targets.shape: (64, 200)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f\"inputs['language_1'].shape: {inputs['language_1'].shape}\")\n",
        "    print(f\"inputs['language_2'].shape: {inputs['language_2'].shape}\")\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "m9tdZcTiefn_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "aVeRR4M9aCQE"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(\n",
        "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "        else:\n",
        "            padding_mask = mask\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask)\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        attention_output_2 = self.layernorm_2(\n",
        "            attention_output_1 + attention_output_2)\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HRNtBW5YaJPj"
      },
      "outputs": [],
      "source": [
        "#PositionalEmbedding layer\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(PositionalEmbedding, self).get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lMyKIYEhaPYM"
      },
      "outputs": [],
      "source": [
        "\n",
        "#End-to-end Transformer\n",
        "\n",
        "embed_dim = 256\n",
        "dense_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"language_1\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"language_2\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfWWY08h2LNf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiIaO1ZMd7pz",
        "outputId": "0d263c07-7b69-4c88-852c-be461920c634"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "63/63 [==============================] - 39s 378ms/step - loss: 2.5840 - accuracy: 0.2510 - val_loss: 1.6405 - val_accuracy: 0.3727\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 22s 345ms/step - loss: 1.6795 - accuracy: 0.3721 - val_loss: 1.4015 - val_accuracy: 0.4537\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 22s 349ms/step - loss: 1.4299 - accuracy: 0.4452 - val_loss: 1.2427 - val_accuracy: 0.5095\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 23s 371ms/step - loss: 1.2788 - accuracy: 0.5013 - val_loss: 1.1976 - val_accuracy: 0.5279\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 24s 377ms/step - loss: 1.1777 - accuracy: 0.5368 - val_loss: 1.1108 - val_accuracy: 0.5559\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 23s 359ms/step - loss: 1.0582 - accuracy: 0.5759 - val_loss: 0.9855 - val_accuracy: 0.5997\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 22s 353ms/step - loss: 1.1272 - accuracy: 0.5636 - val_loss: 0.9067 - val_accuracy: 0.6346\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 23s 368ms/step - loss: 0.9058 - accuracy: 0.6373 - val_loss: 0.8262 - val_accuracy: 0.6639\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 23s 359ms/step - loss: 0.8280 - accuracy: 0.6649 - val_loss: 0.7733 - val_accuracy: 0.6843\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 23s 361ms/step - loss: 0.7965 - accuracy: 0.6781 - val_loss: 0.8461 - val_accuracy: 0.6666\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 23s 368ms/step - loss: 0.7330 - accuracy: 0.7028 - val_loss: 0.6962 - val_accuracy: 0.7162\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 23s 359ms/step - loss: 0.6805 - accuracy: 0.7222 - val_loss: 0.6734 - val_accuracy: 0.7254\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 23s 358ms/step - loss: 0.6511 - accuracy: 0.7333 - val_loss: 0.6450 - val_accuracy: 0.7397\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 23s 359ms/step - loss: 0.6134 - accuracy: 0.7488 - val_loss: 0.5971 - val_accuracy: 0.7549\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 23s 360ms/step - loss: 0.5855 - accuracy: 0.7602 - val_loss: 0.5897 - val_accuracy: 0.7578\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 23s 367ms/step - loss: 0.5482 - accuracy: 0.7743 - val_loss: 0.5555 - val_accuracy: 0.7695\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 23s 367ms/step - loss: 0.5212 - accuracy: 0.7846 - val_loss: 0.5462 - val_accuracy: 0.7747\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 22s 357ms/step - loss: 0.5212 - accuracy: 0.7857 - val_loss: 0.5477 - val_accuracy: 0.7746\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 23s 369ms/step - loss: 0.4890 - accuracy: 0.7983 - val_loss: 0.5297 - val_accuracy: 0.7844\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 23s 360ms/step - loss: 0.4749 - accuracy: 0.8044 - val_loss: 0.5376 - val_accuracy: 0.7848\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 23s 368ms/step - loss: 0.4414 - accuracy: 0.8180 - val_loss: 0.5284 - val_accuracy: 0.7885\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - 23s 358ms/step - loss: 0.4173 - accuracy: 0.8295 - val_loss: 0.4960 - val_accuracy: 0.7995\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - 22s 358ms/step - loss: 0.4131 - accuracy: 0.8320 - val_loss: 0.5191 - val_accuracy: 0.7929\n",
            "Epoch 24/100\n",
            "63/63 [==============================] - 23s 360ms/step - loss: 0.4020 - accuracy: 0.8353 - val_loss: 0.4655 - val_accuracy: 0.8156\n",
            "Epoch 25/100\n",
            "63/63 [==============================] - 23s 363ms/step - loss: 0.3644 - accuracy: 0.8513 - val_loss: 0.4805 - val_accuracy: 0.8106\n",
            "Epoch 26/100\n",
            "63/63 [==============================] - 23s 369ms/step - loss: 0.3553 - accuracy: 0.8544 - val_loss: 0.4692 - val_accuracy: 0.8165\n",
            "Epoch 27/100\n",
            "63/63 [==============================] - 23s 358ms/step - loss: 0.3592 - accuracy: 0.8542 - val_loss: 0.4673 - val_accuracy: 0.8183\n",
            "Epoch 28/100\n",
            "63/63 [==============================] - 23s 361ms/step - loss: 0.3510 - accuracy: 0.8582 - val_loss: 0.4557 - val_accuracy: 0.8227\n",
            "Epoch 29/100\n",
            "63/63 [==============================] - 23s 360ms/step - loss: 0.3520 - accuracy: 0.8582 - val_loss: 0.4791 - val_accuracy: 0.8203\n",
            "Epoch 30/100\n",
            "63/63 [==============================] - 22s 358ms/step - loss: 0.3505 - accuracy: 0.8600 - val_loss: 0.4494 - val_accuracy: 0.8260\n",
            "Epoch 31/100\n",
            "63/63 [==============================] - 23s 358ms/step - loss: 0.3198 - accuracy: 0.8719 - val_loss: 0.4788 - val_accuracy: 0.8181\n",
            "Epoch 32/100\n",
            "63/63 [==============================] - 23s 368ms/step - loss: 0.3021 - accuracy: 0.8781 - val_loss: 0.4332 - val_accuracy: 0.8355\n",
            "Epoch 33/100\n",
            "63/63 [==============================] - 23s 359ms/step - loss: 0.2868 - accuracy: 0.8853 - val_loss: 0.4299 - val_accuracy: 0.8420\n",
            "Epoch 34/100\n",
            "63/63 [==============================] - 22s 356ms/step - loss: 0.2691 - accuracy: 0.8919 - val_loss: 0.4519 - val_accuracy: 0.8378\n",
            "Epoch 35/100\n",
            "63/63 [==============================] - 23s 366ms/step - loss: 0.2678 - accuracy: 0.8928 - val_loss: 0.4713 - val_accuracy: 0.8297\n",
            "Epoch 36/100\n",
            "63/63 [==============================] - 22s 355ms/step - loss: 0.2785 - accuracy: 0.8889 - val_loss: 0.5401 - val_accuracy: 0.8091\n",
            "Epoch 37/100\n",
            "63/63 [==============================] - 23s 357ms/step - loss: 0.2689 - accuracy: 0.8932 - val_loss: 0.4711 - val_accuracy: 0.8209\n",
            "Epoch 38/100\n",
            "63/63 [==============================] - 23s 361ms/step - loss: 0.2823 - accuracy: 0.8884 - val_loss: 0.4345 - val_accuracy: 0.8427\n",
            "Epoch 39/100\n",
            "63/63 [==============================] - 23s 358ms/step - loss: 0.2546 - accuracy: 0.8999 - val_loss: 0.4861 - val_accuracy: 0.8272\n",
            "Epoch 40/100\n",
            "63/63 [==============================] - 23s 368ms/step - loss: 0.2427 - accuracy: 0.9046 - val_loss: 0.4481 - val_accuracy: 0.8375\n",
            "Epoch 41/100\n",
            "63/63 [==============================] - 23s 359ms/step - loss: 0.2367 - accuracy: 0.9072 - val_loss: 0.4167 - val_accuracy: 0.8498\n",
            "Epoch 42/100\n",
            "63/63 [==============================] - 23s 358ms/step - loss: 0.2242 - accuracy: 0.9120 - val_loss: 0.4563 - val_accuracy: 0.8414\n",
            "Epoch 43/100\n",
            "63/63 [==============================] - 23s 360ms/step - loss: 0.2097 - accuracy: 0.9176 - val_loss: 0.4398 - val_accuracy: 0.8474\n",
            "Epoch 44/100\n",
            "63/63 [==============================] - 23s 360ms/step - loss: 0.1951 - accuracy: 0.9232 - val_loss: 0.4572 - val_accuracy: 0.8524\n",
            "Epoch 45/100\n",
            "63/63 [==============================] - 23s 363ms/step - loss: 0.1964 - accuracy: 0.9234 - val_loss: 0.4798 - val_accuracy: 0.8461\n",
            "Epoch 46/100\n",
            "63/63 [==============================] - 22s 356ms/step - loss: 0.1933 - accuracy: 0.9249 - val_loss: 0.4773 - val_accuracy: 0.8493\n",
            "Epoch 47/100\n",
            "63/63 [==============================] - 23s 368ms/step - loss: 0.1873 - accuracy: 0.9280 - val_loss: 0.4790 - val_accuracy: 0.8446\n",
            "Epoch 48/100\n",
            "63/63 [==============================] - 22s 353ms/step - loss: 0.2003 - accuracy: 0.9238 - val_loss: 0.4843 - val_accuracy: 0.8431\n",
            "Epoch 49/100\n",
            "63/63 [==============================] - 23s 368ms/step - loss: 0.1778 - accuracy: 0.9319 - val_loss: 0.4287 - val_accuracy: 0.8653\n",
            "Epoch 50/100\n",
            "63/63 [==============================] - 23s 367ms/step - loss: 0.1697 - accuracy: 0.9351 - val_loss: 0.4424 - val_accuracy: 0.8616\n",
            "Epoch 51/100\n",
            "63/63 [==============================] - 22s 353ms/step - loss: 0.1729 - accuracy: 0.9341 - val_loss: 0.4758 - val_accuracy: 0.8538\n",
            "Epoch 52/100\n",
            "63/63 [==============================] - 22s 354ms/step - loss: 0.1700 - accuracy: 0.9361 - val_loss: 0.4745 - val_accuracy: 0.8508\n",
            "Epoch 53/100\n",
            "63/63 [==============================] - 23s 359ms/step - loss: 0.1640 - accuracy: 0.9385 - val_loss: 0.4532 - val_accuracy: 0.8527\n",
            "Epoch 54/100\n",
            "63/63 [==============================] - 23s 359ms/step - loss: 0.1519 - accuracy: 0.9432 - val_loss: 0.5066 - val_accuracy: 0.8410\n",
            "Epoch 55/100\n",
            "63/63 [==============================] - 23s 360ms/step - loss: 0.1377 - accuracy: 0.9484 - val_loss: 0.4421 - val_accuracy: 0.8623\n",
            "Epoch 56/100\n",
            "63/63 [==============================] - 23s 359ms/step - loss: 0.1375 - accuracy: 0.9490 - val_loss: 0.4721 - val_accuracy: 0.8635\n",
            "Epoch 57/100\n",
            "63/63 [==============================] - 23s 359ms/step - loss: 0.1316 - accuracy: 0.9503 - val_loss: 0.4303 - val_accuracy: 0.8728\n",
            "Epoch 58/100\n",
            "63/63 [==============================] - 23s 361ms/step - loss: 0.1246 - accuracy: 0.9536 - val_loss: 0.4411 - val_accuracy: 0.8701\n",
            "Epoch 59/100\n",
            "63/63 [==============================] - 23s 364ms/step - loss: 0.1210 - accuracy: 0.9548 - val_loss: 0.4710 - val_accuracy: 0.8656\n",
            "Epoch 60/100\n",
            "63/63 [==============================] - 22s 355ms/step - loss: 0.1270 - accuracy: 0.9524 - val_loss: 0.4840 - val_accuracy: 0.8593\n",
            "Epoch 61/100\n",
            "63/63 [==============================] - 23s 362ms/step - loss: 0.1231 - accuracy: 0.9549 - val_loss: 0.4628 - val_accuracy: 0.8627\n",
            "Epoch 62/100\n",
            "63/63 [==============================] - 23s 359ms/step - loss: 0.1207 - accuracy: 0.9559 - val_loss: 0.4486 - val_accuracy: 0.8718\n",
            "Epoch 63/100\n",
            "63/63 [==============================] - 23s 357ms/step - loss: 0.1148 - accuracy: 0.9580 - val_loss: 0.4932 - val_accuracy: 0.8652\n",
            "Epoch 64/100\n",
            "63/63 [==============================] - 23s 362ms/step - loss: 0.1183 - accuracy: 0.9567 - val_loss: 0.4535 - val_accuracy: 0.8704\n",
            "Epoch 65/100\n",
            "63/63 [==============================] - 23s 360ms/step - loss: 0.1037 - accuracy: 0.9620 - val_loss: 0.4973 - val_accuracy: 0.8628\n",
            "Epoch 66/100\n",
            "63/63 [==============================] - 23s 361ms/step - loss: 0.1102 - accuracy: 0.9597 - val_loss: 0.5085 - val_accuracy: 0.8563\n",
            "Epoch 67/100\n",
            "63/63 [==============================] - 22s 353ms/step - loss: 0.1180 - accuracy: 0.9569 - val_loss: 0.4543 - val_accuracy: 0.8678\n",
            "Epoch 68/100\n",
            "63/63 [==============================] - 22s 353ms/step - loss: 0.1172 - accuracy: 0.9573 - val_loss: 0.4831 - val_accuracy: 0.8618\n",
            "Epoch 69/100\n",
            "63/63 [==============================] - 22s 354ms/step - loss: 0.1155 - accuracy: 0.9593 - val_loss: 0.5155 - val_accuracy: 0.8573\n",
            "Epoch 70/100\n",
            "63/63 [==============================] - 23s 363ms/step - loss: 0.1101 - accuracy: 0.9610 - val_loss: 0.5511 - val_accuracy: 0.8496\n",
            "Epoch 71/100\n",
            "63/63 [==============================] - 22s 353ms/step - loss: 0.1076 - accuracy: 0.9615 - val_loss: 0.5148 - val_accuracy: 0.8669\n",
            "Epoch 72/100\n",
            "63/63 [==============================] - 23s 358ms/step - loss: 0.0933 - accuracy: 0.9664 - val_loss: 0.4858 - val_accuracy: 0.8699\n",
            "Epoch 73/100\n",
            "63/63 [==============================] - 23s 363ms/step - loss: 0.0956 - accuracy: 0.9653 - val_loss: 0.4811 - val_accuracy: 0.8702\n",
            "Epoch 74/100\n",
            "63/63 [==============================] - 22s 353ms/step - loss: 0.0943 - accuracy: 0.9662 - val_loss: 0.5045 - val_accuracy: 0.8659\n",
            "Epoch 75/100\n",
            "63/63 [==============================] - 23s 367ms/step - loss: 0.0830 - accuracy: 0.9700 - val_loss: 0.4759 - val_accuracy: 0.8770\n",
            "Epoch 76/100\n",
            "63/63 [==============================] - 23s 360ms/step - loss: 0.0695 - accuracy: 0.9749 - val_loss: 0.4753 - val_accuracy: 0.8806\n",
            "Epoch 77/100\n",
            "63/63 [==============================] - 23s 368ms/step - loss: 0.0647 - accuracy: 0.9769 - val_loss: 0.5187 - val_accuracy: 0.8761\n",
            "Epoch 78/100\n",
            "63/63 [==============================] - 22s 352ms/step - loss: 0.0658 - accuracy: 0.9768 - val_loss: 0.4972 - val_accuracy: 0.8767\n",
            "Epoch 79/100\n",
            "63/63 [==============================] - 23s 362ms/step - loss: 0.0686 - accuracy: 0.9762 - val_loss: 0.4673 - val_accuracy: 0.8793\n",
            "Epoch 80/100\n",
            "63/63 [==============================] - 23s 358ms/step - loss: 0.0710 - accuracy: 0.9748 - val_loss: 0.4669 - val_accuracy: 0.8781\n",
            "Epoch 81/100\n",
            "63/63 [==============================] - 22s 353ms/step - loss: 0.0672 - accuracy: 0.9764 - val_loss: 0.4857 - val_accuracy: 0.8744\n",
            "Epoch 82/100\n",
            "63/63 [==============================] - 22s 353ms/step - loss: 0.0752 - accuracy: 0.9733 - val_loss: 0.4798 - val_accuracy: 0.8725\n",
            "Epoch 83/100\n",
            "63/63 [==============================] - 22s 355ms/step - loss: 0.0775 - accuracy: 0.9724 - val_loss: 0.5066 - val_accuracy: 0.8658\n",
            "Epoch 84/100\n",
            "63/63 [==============================] - 22s 353ms/step - loss: 0.0803 - accuracy: 0.9715 - val_loss: 0.4741 - val_accuracy: 0.8732\n",
            "Epoch 85/100\n",
            "63/63 [==============================] - 22s 354ms/step - loss: 0.0801 - accuracy: 0.9719 - val_loss: 0.4676 - val_accuracy: 0.8775\n",
            "Epoch 86/100\n",
            "63/63 [==============================] - 22s 353ms/step - loss: 0.0760 - accuracy: 0.9734 - val_loss: 0.4840 - val_accuracy: 0.8732\n",
            "Epoch 87/100\n",
            "63/63 [==============================] - 22s 353ms/step - loss: 0.0736 - accuracy: 0.9739 - val_loss: 0.4692 - val_accuracy: 0.8782\n",
            "Epoch 88/100\n",
            "63/63 [==============================] - 22s 354ms/step - loss: 0.0755 - accuracy: 0.9732 - val_loss: 0.5155 - val_accuracy: 0.8703\n",
            "Epoch 89/100\n",
            "63/63 [==============================] - 23s 359ms/step - loss: 0.0620 - accuracy: 0.9783 - val_loss: 0.4900 - val_accuracy: 0.8796\n",
            "Epoch 90/100\n",
            "63/63 [==============================] - 23s 359ms/step - loss: 0.0581 - accuracy: 0.9800 - val_loss: 0.5760 - val_accuracy: 0.8659\n",
            "Epoch 91/100\n",
            "63/63 [==============================] - 23s 368ms/step - loss: 0.0575 - accuracy: 0.9802 - val_loss: 0.5318 - val_accuracy: 0.8772\n",
            "Epoch 92/100\n",
            "63/63 [==============================] - 23s 360ms/step - loss: 0.0571 - accuracy: 0.9804 - val_loss: 0.4935 - val_accuracy: 0.8862\n",
            "Epoch 93/100\n",
            "63/63 [==============================] - 22s 353ms/step - loss: 0.0598 - accuracy: 0.9794 - val_loss: 0.5165 - val_accuracy: 0.8837\n",
            "Epoch 94/100\n",
            "63/63 [==============================] - 23s 359ms/step - loss: 0.0508 - accuracy: 0.9826 - val_loss: 0.5043 - val_accuracy: 0.8863\n",
            "Epoch 95/100\n",
            "63/63 [==============================] - 23s 362ms/step - loss: 0.0442 - accuracy: 0.9848 - val_loss: 0.4999 - val_accuracy: 0.8891\n",
            "Epoch 96/100\n",
            "63/63 [==============================] - 23s 367ms/step - loss: 0.0393 - accuracy: 0.9863 - val_loss: 0.4683 - val_accuracy: 0.8955\n",
            "Epoch 97/100\n",
            "63/63 [==============================] - 22s 353ms/step - loss: 0.0402 - accuracy: 0.9862 - val_loss: 0.5022 - val_accuracy: 0.8875\n",
            "Epoch 98/100\n",
            "63/63 [==============================] - 22s 358ms/step - loss: 0.0378 - accuracy: 0.9869 - val_loss: 0.5037 - val_accuracy: 0.8867\n",
            "Epoch 99/100\n",
            "63/63 [==============================] - 22s 354ms/step - loss: 0.0405 - accuracy: 0.9862 - val_loss: 0.4807 - val_accuracy: 0.8890\n",
            "Epoch 100/100\n",
            "63/63 [==============================] - 23s 361ms/step - loss: 0.0378 - accuracy: 0.9870 - val_loss: 0.5160 - val_accuracy: 0.8831\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45a01565b0>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Training the sequence-to-sequence Transformer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"transformer_model.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"loss\")]\n",
        "\n",
        "transformer.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "transformer.fit(train_ds, epochs=100, validation_data=val_ds, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDC4UNgSaCwl"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# #Translating new sentences with our Transformer model\n",
        "\n",
        "# import numpy as np\n",
        "# spa_vocab = target_vectorization.get_vocabulary()\n",
        "# spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "# max_decoded_sentence_length = 200\n",
        "\n",
        "# def decode_sequence(input_sentence):\n",
        "#     tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "#     decoded_sentence = \"[start]\"\n",
        "#     for i in range(max_decoded_sentence_length):\n",
        "#         tokenized_target_sentence = target_vectorization(\n",
        "#             [decoded_sentence])[:, :-1]\n",
        "#         predictions = transformer(\n",
        "#             [tokenized_input_sentence, tokenized_target_sentence])\n",
        "#         sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "#         sampled_token = spa_index_lookup[sampled_token_index]\n",
        "#         decoded_sentence += \" \" + sampled_token\n",
        "#         if sampled_token == \"[end]\":\n",
        "#             break\n",
        "#     return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KKu0QyLKPWII"
      },
      "outputs": [],
      "source": [
        "# decoded_texts = []  \n",
        "# test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "\n",
        "# for input_sentence in test_eng_texts:\n",
        "#   decoded_sentence = decode_sequence(input_sentence)\n",
        "      \n",
        "#   decoded_sentence = decoded_sentence.replace('[start] ', '').replace(' [end]', '')\n",
        "#   decoded_texts.append(decoded_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NIkybHJePrAS"
      },
      "outputs": [],
      "source": [
        "# total_words = 0\n",
        "# matching = 0\n",
        "# language2_expected_output = [pair[1] for pair in test_pairs]\n",
        "\n",
        "\n",
        "# for i, j in zip(language2_expected_output, decoded_texts):\n",
        "#   i = i.replace('[start] ', '').replace(' [end]', '')\n",
        "#   list1 = i.split()\n",
        "#   list2 = j.split()\n",
        "\n",
        "#   total_words += len(list1)\n",
        "\n",
        "#   for word1, word2 in zip(list1, list2):\n",
        "#     if(word1 == word2):\n",
        "#       matching += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f0JsXztoPtSO"
      },
      "outputs": [],
      "source": [
        "# print(matching/total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGPYNtT3Zl-b"
      },
      "source": [
        "\n",
        "**Running the model and decoding text for test dataset**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: In order to load the model and run the test data on it, please run all the cells of this Jupyter notebook, except the cell which runs model.fit method to train the model. This is because there are many preprocessing steps involved before decoding can be done on test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_ENhK-DsSRvd"
      },
      "outputs": [],
      "source": [
        "def testing(model, test_set):\n",
        "\n",
        "  spa_vocab = target_vectorization.get_vocabulary()\n",
        "  spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "  max_decoded_sentence_length = 200\n",
        "\n",
        "  def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization(\n",
        "            [decoded_sentence])[:, :-1]\n",
        "        predictions = model(\n",
        "            [tokenized_input_sentence, tokenized_target_sentence])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "  \n",
        "  decoded_texts = []  \n",
        "  for input_sentence in test_set:\n",
        "    decoded_sentence = decode_sequence(input_sentence)\n",
        "      \n",
        "    decoded_sentence = decoded_sentence.replace('[start] ', '').replace(' [end]', '')\n",
        "    decoded_texts.append(decoded_sentence)\n",
        "\n",
        "  return decoded_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qS4qN9faLwo_"
      },
      "outputs": [],
      "source": [
        "#Please run the below code for testing\n",
        "import pickle\n",
        "import keras\n",
        "\n",
        "#Test file\n",
        "test_input_texts = pickle.load(open('DS_5_test_input', 'rb'))\n",
        "\n",
        "#the keras model sent in email for the project\n",
        "model = keras.models.load_model(\n",
        "    \"transformer_model.keras\",\n",
        "    custom_objects={\"TransformerDecoder\": TransformerDecoder,\n",
        "                    \"TransformerEncoder\": TransformerEncoder,\n",
        "                    \"PositionalEmbedding\": PositionalEmbedding})\n",
        "\n",
        "#decoded_texts = testing(model, test_input_texts)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY8dZySRSGyS"
      },
      "source": [
        "Decoding test data in sets of 1000 because of GPU crashes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "I6g0mCHW_MSz"
      },
      "outputs": [],
      "source": [
        "decoded_texts_1 = testing(model, test_input_texts[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "f6jKGpGt9jUV"
      },
      "outputs": [],
      "source": [
        "pickle.dump(decoded_texts_1, open('/content/drive/MyDrive/Colab Notebooks/project2/translated_test_texts1000','wb')) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xe0m2fL8Ocxj"
      },
      "outputs": [],
      "source": [
        "len(decoded_texts_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ZturX787_NL2"
      },
      "outputs": [],
      "source": [
        "decoded_texts_2 = testing(model, test_input_texts[1000:2000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9zt28SoY9n2g"
      },
      "outputs": [],
      "source": [
        "pickle.dump(decoded_texts_2, open('/content/drive/MyDrive/Colab Notebooks/project2/translated_test_texts2000','wb')) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5N8TlXfL3E_t"
      },
      "outputs": [],
      "source": [
        "decoded_texts_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "-tufaWQ7Okui"
      },
      "outputs": [],
      "source": [
        "decoded_texts_3 = testing(model, test_input_texts[2000:3000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "2Z1w9UnOE5-z"
      },
      "outputs": [],
      "source": [
        "pickle.dump(decoded_texts_3, open('/content/drive/MyDrive/Colab Notebooks/project2/translated_test_texts3000','wb')) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "rfrdl6PMOlIF"
      },
      "outputs": [],
      "source": [
        "decoded_texts_4 = testing(model, test_input_texts[3000:4000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "9Orcf8c5FBMa"
      },
      "outputs": [],
      "source": [
        "pickle.dump(decoded_texts_4, open('/content/drive/MyDrive/Colab Notebooks/project2/translated_test_texts4000','wb')) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "_nfdjh96OleV"
      },
      "outputs": [],
      "source": [
        "decoded_texts_5 = testing(model, test_input_texts[4000:5000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "w8ptuHOVFGJ9"
      },
      "outputs": [],
      "source": [
        "pickle.dump(decoded_texts_5, open('/content/drive/MyDrive/Colab Notebooks/project2/translated_test_texts5000','wb')) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DL1bg9pzSk1X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwyfTGXtSlym"
      },
      "source": [
        "Loading all decoded texts into one file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "lXxS2NcIEuVc"
      },
      "outputs": [],
      "source": [
        "decoded_text_2000 = pickle.load(open('/content/drive/MyDrive/Colab Notebooks/project2/translated_test_texts2000','rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "XbvQXpOS0PLQ"
      },
      "outputs": [],
      "source": [
        "decoded_text_1000 = pickle.load(open('/content/drive/MyDrive/Colab Notebooks/project2/translated_test_texts1000','rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "KiJo1Qlazluz"
      },
      "outputs": [],
      "source": [
        "decoded_text_3000 = pickle.load(open('/content/drive/MyDrive/Colab Notebooks/project2/translated_test_texts3000','rb')) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "rQl4o0Rxzoo9"
      },
      "outputs": [],
      "source": [
        "decoded_text_4000 = pickle.load(open('/content/drive/MyDrive/Colab Notebooks/project2/translated_test_texts4000','rb')) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "CYW5TR-tzrAB"
      },
      "outputs": [],
      "source": [
        "decoded_text_5000 = pickle.load(open('/content/drive/MyDrive/Colab Notebooks/project2/translated_test_texts5000','rb')) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "i1KKM-rkSt36"
      },
      "outputs": [],
      "source": [
        "decoded_list = decoded_text_1000 + decoded_text_2000 + decoded_text_3000 + decoded_text_4000 + decoded_text_5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YimsPWMfdmv2",
        "outputId": "51069e7c-afb2-4740-d9f0-15b7a5f369e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(decoded_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LW0LhJnedwh-"
      },
      "outputs": [],
      "source": [
        "decoded_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "8lZZIgmQTSmv"
      },
      "outputs": [],
      "source": [
        "pickle.dump(decoded_list, open('/content/drive/MyDrive/Colab Notebooks/project2/final_output_data','wb')) "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
